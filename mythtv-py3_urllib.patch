--- mythtv/programs/scripts/internetcontent/nv_python_libs/mtv/mtv_api.py	(original)
+++ mythtv/programs/scripts/internetcontent/nv_python_libs/mtv/mtv_api.py	(refactored)
@@ -37,7 +37,7 @@
 
 import os, struct, sys, re, time
 from datetime import datetime, timedelta
-import urllib, urllib2
+import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse
 import logging
 
 try:
@@ -84,7 +84,7 @@
 
     def _grabUrl(self, url):
         try:
-            urlhandle = urllib.urlopen(url)
+            urlhandle = urllib.request.urlopen(url)
         except IOError, errormsg:
             raise MtvHttpError(errormsg)
         return urlhandle.read()
@@ -355,7 +355,7 @@
         return an array of matching item dictionaries
         return
         '''
-        url = self.config[u'urls'][u'video.search'] % (urllib.quote_plus(title.encode("utf-8")), pagenumber , pagelen,)
+        url = self.config[u'urls'][u'video.search'] % (urllib.parse.quote_plus(title.encode("utf-8")), pagenumber , pagelen,)
         if self.config['debug_enabled']:
             print url
             print
@@ -403,7 +403,7 @@
 
             video_details = None
             try:
-                video_details = self.videoDetails(item['id'], urllib.quote(item['title'].encode("utf-8")))
+                video_details = self.videoDetails(item['id'], urllib.parse.quote(item['title'].encode("utf-8")))
             except MtvUrlError, msg:
                 sys.stderr.write(self.error_messages['MtvUrlError'] % msg)
             except MtvVideoDetailError, msg:
@@ -752,7 +752,7 @@
                 metadata['video'] = metadata['link']
             else:
                 index = metadata['video'].rindex(u':')
-                metadata['video'] = self.mtvHtmlPath % (urllib.quote(metadata['title'].encode("utf-8")), metadata['video'][index+1:])
+                metadata['video'] = self.mtvHtmlPath % (urllib.parse.quote(metadata['title'].encode("utf-8")), metadata['video'][index+1:])
                 metadata['link'] =  metadata['video']
                 # !! This tag will need to be added at a later date
 #                metadata['customhtml'] = u'true'
--- mythtv/programs/scripts/internetcontent/nv_python_libs/youtube/youtube_api.py	(original)
+++ mythtv/programs/scripts/internetcontent/nv_python_libs/youtube/youtube_api.py	(refactored)
@@ -37,7 +37,7 @@
 # 0.3.0 Adapted to the v3 API
 
 import os, struct, sys, re, time, shutil
-import urllib, urllib2
+import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse
 import json
 import logging
 from MythTV import MythXML
@@ -61,7 +61,7 @@
 
     def getJson(self):
         try:
-            urlhandle = urllib.urlopen(self.url)
+            urlhandle = urllib.request.urlopen(self.url)
             return json.load(urlhandle)
         except IOError, errormsg:
             raise YouTubeHttpError(errormsg)
@@ -246,7 +246,7 @@
         def getExternalIP():
             '''Find the external IP address of this computer.
             '''
-            url = urllib.URLopener()
+            url = urllib.request.URLopener()
             try:
                 resp = url.open('http://www.whatismyip.com/automation/n09230945.asp')
                 return resp.read()
@@ -260,15 +260,15 @@
             return {}
 
         try:
-            gs = urllib.urlopen('http://blogama.org/ip_query.php?ip=%s&output=xml' % ip)
+            gs = urllib.request.urlopen('http://blogama.org/ip_query.php?ip=%s&output=xml' % ip)
             txt = gs.read()
         except:
             try:
-                gs = urllib.urlopen('http://www.seomoz.org/ip2location/look.php?ip=%s' % ip)
+                gs = urllib.request.urlopen('http://www.seomoz.org/ip2location/look.php?ip=%s' % ip)
                 txt = gs.read()
             except:
                 try:
-                    gs = urllib.urlopen('http://api.hostip.info/?ip=%s' % ip)
+                    gs = urllib.request.urlopen('http://api.hostip.info/?ip=%s' % ip)
                     txt = gs.read()
                 except:
                     logging.error('GeoIP servers not available')
@@ -403,7 +403,7 @@
         url = ('https://www.googleapis.com/youtube/v3/search?part=snippet&' + \
                 'type=video&q=%s&maxResults=%s&order=relevance&' + \
                 'videoEmbeddable=true&key=%s&pageToken=%s') % \
-                (urllib.quote_plus(title.encode("utf-8")), pagelen, self.apikey,
+                (urllib.parse.quote_plus(title.encode("utf-8")), pagelen, self.apikey,
                         pagenumber)
         if self.config['debug_enabled']:
             print url
--- mythtv/programs/scripts/internetcontent/nv_python_libs/dailymotion/dailymotion_api.py	(original)
+++ mythtv/programs/scripts/internetcontent/nv_python_libs/dailymotion/dailymotion_api.py	(refactored)
@@ -35,7 +35,7 @@
 
 
 import os, struct, sys, re, time
-import urllib, urllib2
+import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse
 import logging
 from MythTV import MythXML
 
@@ -83,7 +83,7 @@
 
     def _grabUrl(self, url):
         try:
-            urlhandle = urllib.urlopen(url)
+            urlhandle = urllib.request.urlopen(url)
         except IOError, errormsg:
             raise DailymotionHttpError(errormsg)
         return urlhandle.read()
@@ -556,7 +556,7 @@
         def getExternalIP():
             '''Find the external IP address of this computer.
             '''
-            url = urllib.URLopener()
+            url = urllib.request.URLopener()
             try:
                 resp = url.open('http://www.whatismyip.com/automation/n09230945.asp')
                 return resp.read()
@@ -570,15 +570,15 @@
             return {}
 
         try:
-            gs = urllib.urlopen('http://blogama.org/ip_query.php?ip=%s&output=xml' % ip)
+            gs = urllib.request.urlopen('http://blogama.org/ip_query.php?ip=%s&output=xml' % ip)
             txt = gs.read()
         except:
             try:
-                gs = urllib.urlopen('http://www.seomoz.org/ip2location/look.php?ip=%s' % ip)
+                gs = urllib.request.urlopen('http://www.seomoz.org/ip2location/look.php?ip=%s' % ip)
                 txt = gs.read()
             except:
                 try:
-                    gs = urllib.urlopen('http://api.hostip.info/?ip=%s' % ip)
+                    gs = urllib.request.urlopen('http://api.hostip.info/?ip=%s' % ip)
                     txt = gs.read()
                 except:
                     logging.error('GeoIP servers not available')
@@ -709,7 +709,7 @@
         return an array of matching item dictionaries
         return
         '''
-        url = self.config[u'urls'][u'video.search'] % (urllib.quote_plus(title.encode("utf-8")), pagenumber)
+        url = self.config[u'urls'][u'video.search'] % (urllib.parse.quote_plus(title.encode("utf-8")), pagenumber)
         if self.config['debug_enabled']:
             print url
             print
--- mythtv/programs/scripts/internetcontent/nv_python_libs/vimeo/vimeo_api.py	(original)
+++ mythtv/programs/scripts/internetcontent/nv_python_libs/vimeo/vimeo_api.py	(refactored)
@@ -55,7 +55,7 @@
 Python module to interact with Vimeo through its API (version 2)
 """
 import os, struct, sys, re, time, datetime
-import urllib, urllib2
+import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse
 import logging
 import pycurl
 import xml.etree.ElementTree as ET
@@ -908,7 +908,7 @@
 #        print xml_data
 
         try:
-            xml_data = self.client.vimeo_videos_search(urllib.quote_plus(title.encode("utf-8")),
+            xml_data = self.client.vimeo_videos_search(urllib.parse.quote_plus(title.encode("utf-8")),
                              sort='most_liked',
                              per_page=pagelen,
                              page=pagenumber)
--- mythtv/programs/scripts/internetcontent/nv_python_libs/bliptv/bliptv_api.py	(original)
+++ mythtv/programs/scripts/internetcontent/nv_python_libs/bliptv/bliptv_api.py	(refactored)
@@ -38,7 +38,7 @@
 #       Removed a subdirectory level as the "Featured" RSS feed has been discontinued
 
 import os, struct, sys, re, time
-import urllib, urllib2
+import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse
 import logging
 from MythTV import MythXML
 
@@ -86,7 +86,7 @@
 
     def _grabUrl(self, url):
         try:
-            urlhandle = urllib.urlopen(url)
+            urlhandle = urllib.request.urlopen(url)
         except IOError, errormsg:
             raise BliptvHttpError(errormsg)
         return urlhandle.read()
@@ -269,7 +269,7 @@
         def getExternalIP():
             '''Find the external IP address of this computer.
             '''
-            url = urllib.URLopener()
+            url = urllib.request.URLopener()
             try:
                 resp = url.open('http://www.whatismyip.com/automation/n09230945.asp')
                 return resp.read()
@@ -283,15 +283,15 @@
             return {}
 
         try:
-            gs = urllib.urlopen('http://blogama.org/ip_query.php?ip=%s&output=xml' % ip)
+            gs = urllib.request.urlopen('http://blogama.org/ip_query.php?ip=%s&output=xml' % ip)
             txt = gs.read()
         except:
             try:
-                gs = urllib.urlopen('http://www.seomoz.org/ip2location/look.php?ip=%s' % ip)
+                gs = urllib.request.urlopen('http://www.seomoz.org/ip2location/look.php?ip=%s' % ip)
                 txt = gs.read()
             except:
                 try:
-                    gs = urllib.urlopen('http://api.hostip.info/?ip=%s' % ip)
+                    gs = urllib.request.urlopen('http://api.hostip.info/?ip=%s' % ip)
                     txt = gs.read()
                 except:
                     logging.error('GeoIP servers not available')
@@ -422,7 +422,7 @@
         return an array of matching item dictionaries
         return
         '''
-        url = self.config[u'urls'][u'video.search'] % (urllib.quote_plus(title.encode("utf-8")), pagenumber, pagelen, self.config['language'])
+        url = self.config[u'urls'][u'video.search'] % (urllib.parse.quote_plus(title.encode("utf-8")), pagenumber, pagelen, self.config['language'])
 
         if self.config['debug_enabled']:
             print "Search URL:"
--- mythtv/programs/scripts/hardwareprofile/request.py	(original)
+++ mythtv/programs/scripts/hardwareprofile/request.py	(refactored)
@@ -21,15 +21,15 @@
 # providing the base url, user agent, and proxy information.
 # The object returned is slightly modified, with a shortcut to urlopen.
 
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 import urlparse
 
-class _Request( urllib2.Request ):
+class _Request( urllib.request.Request ):
     timeout = None
     def open(self):
         if self.timeout:
-            return urllib2.urlopen(self, None, self.timeout)
-        return urllib2.urlopen(self)
+            return urllib.request.urlopen(self, None, self.timeout)
+        return urllib.request.urlopen(self)
 
 class _RequestFactory( object ):
     def __init__(self, baseurl, user_agent, timeout, proxy):
--- mythtv/programs/scripts/hardwareprofile/smolt.py	(original)
+++ mythtv/programs/scripts/hardwareprofile/smolt.py	(refactored)
@@ -42,8 +42,8 @@
 import os
 from urlparse import urljoin
 from urlparse import urlparse
-from urllib import urlencode
-import urllib
+from urllib.parse import urlencode
+import urllib.request, urllib.parse, urllib.error
 import json
 from json import JSONEncoder
 import datetime
@@ -59,7 +59,7 @@
 from logging.handlers import RotatingFileHandler
 import codecs
 import MultipartPostHandler
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 
 try:
     import subprocess
@@ -730,7 +730,7 @@
         request_url = urljoin(smoonURL + "/", entry_point, False)
         logging.debug('Sending request to %s' % request_url)
         try:
-            opener = urllib2.build_opener(MultipartPostHandler.MultipartPostHandler)
+            opener = urllib.request.build_opener(MultipartPostHandler.MultipartPostHandler)
             params = {  'uuid':self.host.UUID,
                         'host':serialized_host_obj_machine,
                         'token':tok,
--- mythtv/programs/scripts/hardwareprofile/distros/mythtv_data/request.py	(original)
+++ mythtv/programs/scripts/hardwareprofile/distros/mythtv_data/request.py	(refactored)
@@ -21,15 +21,15 @@
 # providing the base url, user agent, and proxy information.
 # The object returned is slightly modified, with a shortcut to urlopen.
 
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 import urlparse
 
-class _Request( urllib2.Request ):
+class _Request( urllib.request.Request ):
     timeout = None
     def open(self):
         if self.timeout:
-            return urllib2.urlopen(self, None, self.timeout)
-        return urllib2.urlopen(self)
+            return urllib.request.urlopen(self, None, self.timeout)
+        return urllib.request.urlopen(self)
 
 class _RequestFactory( object ):
     def __init__(self, baseurl, user_agent, timeout, proxy):
--- mythtv/programs/scripts/hardwareprofile/MultipartPostHandler.py	(original)
+++ mythtv/programs/scripts/hardwareprofile/MultipartPostHandler.py	(refactored)
@@ -41,8 +41,8 @@
   then uploads it to the W3C validator.
 """
 
-import urllib
-import urllib2
+import urllib.request, urllib.parse, urllib.error
+import urllib.request, urllib.error, urllib.parse
 import mimetools, mimetypes
 import os, stat
 from cStringIO import StringIO
@@ -55,8 +55,8 @@
 #  assigning a sequence.
 doseq = 1
 
-class MultipartPostHandler(urllib2.BaseHandler):
-    handler_order = urllib2.HTTPHandler.handler_order - 10 # needs to run first
+class MultipartPostHandler(urllib.request.BaseHandler):
+    handler_order = urllib.request.HTTPHandler.handler_order - 10 # needs to run first
 
     def http_request(self, request):
         data = request.get_data()
@@ -74,7 +74,7 @@
                 raise TypeError, "not a valid non-string sequence or mapping object", traceback
 
             if len(v_files) == 0:
-                data = urllib.urlencode(v_vars, doseq)
+                data = urllib.parse.urlencode(v_vars, doseq)
             else:
                 boundary, data = self.multipart_encode(v_vars, v_files)
 
@@ -118,7 +118,7 @@
     import tempfile, sys
 
     validatorURL = "http://validator.w3.org/check"
-    opener = urllib2.build_opener(MultipartPostHandler)
+    opener = urllib.request.build_opener(MultipartPostHandler)
 
     def validateFile(url):
         temp = tempfile.mkstemp(suffix=".html")
--- mythtv/programs/scripts/metadata/Music/lyrics/lyricswiki.py	(original)
+++ mythtv/programs/scripts/metadata/Music/lyrics/lyricswiki.py	(refactored)
@@ -1,5 +1,5 @@
 #-*- coding: UTF-8 -*-
-import sys, re, urllib2, socket, HTMLParser
+import sys, re, urllib.request, urllib.error, urllib.parse, socket, HTMLParser
 from optparse import OptionParser
 
 if sys.version_info < (2, 7):
@@ -31,7 +31,7 @@
         utilities.log(debug,  "%s: searching lyrics for %s - %s - %s" % (__title__, lyrics.artist, lyrics.album, lyrics.title))
 
         try:
-            req = urllib2.urlopen(self.url % (urllib2.quote(lyrics.artist), urllib2.quote(lyrics.title)))
+            req = urllib.request.urlopen(self.url % (urllib.parse.quote(lyrics.artist), urllib.parse.quote(lyrics.title)))
             response = req.read()
         except:
             return False
@@ -44,9 +44,9 @@
         if not self.page.endswith('action=edit'):
             utilities.log(debug, "%s: search url: %s" % (__title__, self.page))
             try:
-                req = urllib2.urlopen(self.page)
+                req = urllib.request.urlopen(self.page)
                 response = req.read()
-            except urllib2.HTTPError, error: # strange... sometimes lyrics are returned with a 404 error
+            except urllib.error.HTTPError, error: # strange... sometimes lyrics are returned with a 404 error
                 if error.code == 404:
                     response = error.read()
                 else:
--- mythtv/programs/scripts/metadata/Music/lyrics/genius.py	(original)
+++ mythtv/programs/scripts/metadata/Music/lyrics/genius.py	(refactored)
@@ -5,8 +5,8 @@
 taxigps
 """
 import sys
-import urllib
-import urllib2
+import urllib.request, urllib.parse, urllib.error
+import urllib.request, urllib.error, urllib.parse
 import socket
 import re
 import chardet
@@ -42,9 +42,9 @@
         utilities.log(debug, "%s: searching lyrics for %s - %s - %s" % (__title__, lyrics.artist, lyrics.album, lyrics.title))
 
         try:
-            request = urllib2.Request(self.url % (urllib2.quote(lyrics.artist), '%20', urllib2.quote(lyrics.title)))
+            request = urllib.request.Request(self.url % (urllib.parse.quote(lyrics.artist), '%20', urllib.parse.quote(lyrics.title)))
             request.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; rv:25.0) Gecko/20100101 Firefox/25.0')
-            req = urllib2.urlopen(request)
+            req = urllib.request.urlopen(request)
             response = req.read()
         except:
             return False
@@ -60,9 +60,9 @@
         utilities.log(debug, "%s: search url: %s" % (__title__, self.page))
 
         try:
-            request = urllib2.Request(self.page)
+            request = urllib.request.Request(self.page)
             request.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; rv:25.0) Gecko/20100101 Firefox/25.0')
-            req = urllib2.urlopen(request)
+            req = urllib.request.urlopen(request)
             response = req.read()
         except:
             return False
--- mythtv/programs/scripts/metadata/Music/lyrics/darklyrics.py	(original)
+++ mythtv/programs/scripts/metadata/Music/lyrics/darklyrics.py	(refactored)
@@ -6,7 +6,7 @@
 """
 
 import hashlib
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 import re
 import chardet
 import sys
@@ -29,10 +29,10 @@
         self.searchUrl = "http://www.darklyrics.com/search?q=%term%"
 
     def search(self, artist, title):
-        term = urllib2.quote((artist if artist else "") + " " + (title if title else ""));
+        term = urllib.parse.quote((artist if artist else "") + " " + (title if title else ""));
 
         try:
-            request = urllib2.urlopen(self.searchUrl.replace("%term%", term))
+            request = urllib.request.urlopen(self.searchUrl.replace("%term%", term))
             searchResponse = request.read();
         except:
             return None
@@ -59,7 +59,7 @@
 
     def findLyrics(self, url, index):
         try:
-            request = urllib2.urlopen(url);
+            request = urllib.request.urlopen(url);
             res = request.read();
         except:
             return None
@@ -81,7 +81,7 @@
 
     def getAlbumName(self, url):
         try:
-            request = urllib2.urlopen(url);
+            request = urllib.request.urlopen(url);
             res = request.read();
         except:
             return "";
--- mythtv/programs/scripts/metadata/Music/lyrics/lyricscom.py	(original)
+++ mythtv/programs/scripts/metadata/Music/lyrics/lyricscom.py	(refactored)
@@ -7,8 +7,8 @@
 
 import sys
 import re
-import urllib
-import urllib2
+import urllib.request, urllib.parse, urllib.error
+import urllib.request, urllib.error, urllib.parse
 import socket
 import difflib
 from optparse import OptionParser
@@ -39,7 +39,7 @@
             return False
 
         try:
-            request = urllib2.urlopen(self.url % urllib.quote_plus(lyrics.artist))
+            request = urllib.request.urlopen(self.url % urllib.parse.quote_plus(lyrics.artist))
             response = request.read()
         except:
             return False
@@ -54,7 +54,7 @@
         if url:
             utilities.log(debug, "%s: Artist url is %s"  % (__title__, url))
             try:
-                req = urllib2.urlopen(url)
+                req = urllib.request.urlopen(url)
                 resp = req.read()
             except:
                 return False
@@ -70,7 +70,7 @@
                 utilities.log(debug, "%s: Song url is %s"  % (__title__, url))
 
                 try:
-                    req2 = urllib2.urlopen(url)
+                    req2 = urllib.request.urlopen(url)
                     resp2 = req2.read()
                 except:
                     return False
--- mythtv/programs/scripts/metadata/Music/lyrics/alsong.py	(original)
+++ mythtv/programs/scripts/metadata/Music/lyrics/alsong.py	(refactored)
@@ -6,7 +6,7 @@
 
 import sys
 import socket
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 import difflib
 import xml.dom.minidom as xml
 from optparse import OptionParser
@@ -49,8 +49,8 @@
 
         try:
             headers = {'Content-Type':'text/xml; charset=utf-8'}
-            request = urllib2.Request(ALSONG_URL, ALSONG_TMPL % (lyrics.title, lyrics.artist), headers)
-            response = urllib2.urlopen(request)
+            request = urllib.request.Request(ALSONG_URL, ALSONG_TMPL % (lyrics.title, lyrics.artist), headers)
+            response = urllib.request.urlopen(request)
             Page = response.read()
         except:
             return False
--- mythtv/programs/scripts/metadata/Music/musicbrainzngs/compat.py	(original)
+++ mythtv/programs/scripts/metadata/Music/musicbrainzngs/compat.py	(refactored)
@@ -39,12 +39,11 @@
 
 if is_py2:
 	from StringIO import StringIO
-	from urllib2 import HTTPPasswordMgr, HTTPDigestAuthHandler, Request,\
-						HTTPHandler, build_opener, HTTPError, URLError,\
-						build_opener
+	from urllib.request import HTTPPasswordMgr, HTTPDigestAuthHandler, Request, HTTPHandler, build_opener, build_opener
+	from urllib.error import HTTPError, URLError
 	from httplib import BadStatusLine, HTTPException
 	from urlparse import urlunparse
-	from urllib import urlencode
+	from urllib.parse import urlencode
 
 	bytes = str
 	unicode = unicode
--- mythtv/bindings/python/tmdb3/tmdb3/request.py	(original)
+++ mythtv/bindings/python/tmdb3/tmdb3/request.py	(refactored)
@@ -14,10 +14,10 @@
 
 # supports python2 and python3
 try:
-    from urllib  import urlencode
-    from urllib2 import Request   as _py23Request
-    from urllib2 import urlopen   as _py23urlopen
-    from urllib2 import HTTPError as _py23HTTPError
+    from urllib.parse  import urlencode
+    from urllib.request import Request   as _py23Request
+    from urllib.request import urlopen   as _py23urlopen
+    from urllib.error import HTTPError as _py23HTTPError
 
 except (NameError, ImportError):
     from urllib.parse   import urlencode
--- mythtv/bindings/python/MythTV/connections.py	(original)
+++ mythtv/bindings/python/MythTV/connections.py	(refactored)
@@ -17,7 +17,7 @@
 import lxml.etree as etree
 import weakref
 try:
-    import urllib2
+    import urllib.request, urllib.error, urllib.parse
 except ImportError:
     import urllib.request as urllib2
 import socket
@@ -575,8 +575,8 @@
         either 'backend' or 'port' is not defined.
     """
 
-    class _Request( urllib2.Request ):
-        def open(self): return urllib2.urlopen(self)
+    class _Request( urllib.request.Request ):
+        def open(self): return urllib.request.urlopen(self)
         def read(self): return self.open().read()
 
         def setJSON(self):
@@ -620,7 +620,7 @@
         url = 'http://{0.host}:{0.port}/{1}'.format(self, path)
         if keyvars:
             url += '?' + '&'.join(
-                        ['{0}={1}'.format(k,urllib2.quote(v))
+                        ['{0}={1}'.format(k,urllib.parse.quote(v))
                                 for k,v in keyvars.items()])
         self.log(self.log.NETWORK, self.log.DEBUG, 'Generating request', url)
         return self._Request(url)
